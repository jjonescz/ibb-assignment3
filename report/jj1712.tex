% ============================================================================================
% This is a LaTeX template used for the course
%
%  I M A G E   B A S E D   B I O M E T R I C S
%
% Faculty of Computer and Information Science
% University of Ljubljana
% Slovenia, EU
%
% You can use this template for whatever reason you like.
% If you have any questions feel free to contact
% ziga.emersic@fri.uni-lj.si
% ============================================================================================

\documentclass[9pt]{IEEEtran}

% basic
\usepackage[english]{babel}
\usepackage{graphicx,epstopdf,fancyhdr,amsmath,amsthm,amssymb,url,array,textcomp,svg,listings,hyperref,xcolor,colortbl,float,gensymb,longtable,supertabular,multicol,placeins}

 % `sumniki' in names
\usepackage[utf8x]{inputenc}

 % search and copy for `sumniki'
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\input{glyphtounicode}
\pdfgentounicode=1

% tidy figures
\graphicspath{{../figures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg,.eps}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor trig-gs}

% ============================================================================================

\title{\vspace{0ex} %
Ear Recognition
\\ \large{Assignment \#3}\\ \normalsize{Image Based Biometrics 2020/21, Faculty of Computer and Information Science, University of Ljubljana}}
\author{ %
Jan~Jone≈°
\vspace{-4.0ex}
}

% ============================================================================================

\begin{document}

\maketitle

\begin{abstract}
    Ears as biometric modality for identity recognition have several advantages.
    It is highly universal modality and easily obtainable from images of people.
    On the other hand, focus of image-based biometric research lies elsewhere (e.g., face recognition).
    Therefore, high-quality datasets consisting of cropped and labeled ear images are scarce.
    This poses a challenge for deep neural networks that otherwise provide state-of-the-art solutions for image classification tasks but were introduced in ear recognition research only recently.
    In this paper we train deep neural network classifier on readily-available annotated ear dataset.
    Due to low amount of data points available for training, we employ transfer learning and experiment with image augmentations.
    We are able to achieve accuracy 19.60~\% on unseen test data.
\end{abstract}

\section{Introduction}

Convolutional neural networks (CNNs) are used to solve various image-based tasks from segmentation~\cite{chen2014semantic} to object detection~\cite{tan2020efficientdet}.
They have also recently been used for ear recognition~\cite{emersic2017,dodge2018,emersic2019,eyiokur2017,zhang2018}.

In this paper we build and evaluate CNN model intended to be used as recognition stage in biometric pipeline with ear modality.
Our model accepts image of an ear at its input and produces subject identification at its output.
Input image is expected to be cropped so that only the ear is visible.
If we wanted the whole pipeline to accept images of people as inputs, a~separate CNN-based ear detector~\cite{emersic2018} could be used as previous stage in the biometric pipeline.

Since ears are not the prevalent modality in image-based authentication, high-quality datasets containing annotated ear images are scarce and they usually consist of relatively few datapoints.
We approach this problem in two ways:
\begin{enumerate}
    \item We build our model upon publicly available CNN model pre-trained for image classification.
          This model has been trained on datasets much larger than ours.
          We use its weights as our starting point and employ transfer learning to adapt this model for ear image classification.
    \item We analyze impact of image augmentation on the ear dataset used for training our CNN model.
          We hypothesize that image augmentation could improve the model's ability to generalize even from relatively small dataset because the input data are more varied.
\end{enumerate}

\section{Methodology}\label{sec:meth}

We use closed-set experimentation protocol where number of subjects is predetermined and therefore we effectively solve a~classification task.

Our CNN model is based on EfficientNet-B0 model~\cite{efficientNet} pre-trained on ImageNet~\cite{imageNet} without its top fully-connected layer that was used for the original classification.
We instead append our own classification head.
The network ends with softmax activation to classify the subjects.
During training we freeze EfficientNet weights and train only the appended layers.

We also experiment with image augmentations where each training image can be randomly flipped horizontally, resized, cropped or have its brightness adjusted.

\section{Experiments and results}

We use AWE~\cite{emersic2017ear}, a dataset of ear images scraped from the Internet.
It contains data of 100 subjects, 10 cropped ear images per subject.
We split images into train, validation and test sets of 500, 250 and 250 images, respectively.
All images are resized to $128 \times 128$ pixels and batch size is set to 64.

We train two models---one on the original training dataset (Model A) and another on augmented images as described in Section~\ref{sec:meth} (Model B).
Both models use classification head consisting of two fully-connected layers with 512 units, each followed by ReLU activation and dropout with rate 0.5 and are trained with Adam optimizer using learning rate $10^{-3}$ for first 35 epochs and decreased to $10^{-4}$ for next 35 epochs.
We have used accuracy on validation set during training (Figure~\ref{fig:acc}) to determine hyperparameters and architecture of the CNN.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\columnwidth]{acc}
    \caption{Evolution of models' accuracy during training.
    Accuracy is computed after each epoch on both training and validation sets.}
    \label{fig:acc}
\end{figure}

Performance of both models is evaluated using Rank-1 and Rank-5 recognition rates, cumulative match-score curve (CMC) and area under the CMC curve (AUCMC).

CMC curve of Model B is worse for most ranks than that of Model A (Figure~\ref{fig:cmc}) and so is overall area under the curve (Table~\ref{tab:metrics}).
Furthermore, both Rank-1 and Rank-5 recognition rates of Model A are significantly better than those of Model B (Table~\ref{tab:metrics}).
These results tell us that our image augmentations are not enough to make the CNN generalize well.

From accuracy on validation data observed during training (Figure~\ref{fig:acc}), we expect to get around 60~\% accuracy on unseen test set.
We obtain significantly worse results (Table~\ref{tab:metrics}) and we hypothesize that it is due to insufficient regularization and low amount of training data.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\columnwidth]{cmc}
    \caption{CMC curves on test set for models trained on original and augmented datasets, respectively.}
    \label{fig:cmc}
\end{figure}

\begin{table}[ht]
    \caption{Performance metrics of models on test set.}
    \label{tab:metrics}
    \centering
    \begin{tabular}{llll}
        Augmentations & Rank-1 [\%] & Rank-5 [\%] & AUCMC [\%] \\
        \hline
        No & 19.60 & 42.80 & 80.46 \\
        Yes & 14.40 & 32.00 & 78.53
    \end{tabular}
\end{table}

\section{Conclusion}

We trained and analyzed a CNN-based ear recognition system using transfer learning.
We also experimented with image augmentations although we did not achieve the desired generalization effect with them.

Our model did not perform on unseen test data as well as expected although we employed regularization techniques (dropout layers and image augmentations).
We therefore conclude that either different regularization techniques or larger and more diverse training dataset would be needed to obtain better results.

For a real-world authentication system, we would need to modify our CNN model for the open-set recognition problem.
Future work could also focus on fine-tuning the pre-trained model and analyzing whether another model could be more suitable than EfficientNet.

Our CNN training and evaluation code is available online at \texttt{\url{https://github.com/jjonescz/ibb-assignment3}}.

\bibliographystyle{IEEEtran}
\bibliography{bibliography}

\end{document}
