% ============================================================================================
% This is a LaTeX template used for the course
%
%  I M A G E   B A S E D   B I O M E T R I C S
%
% Faculty of Computer and Information Science
% University of Ljubljana
% Slovenia, EU
%
% You can use this template for whatever reason you like.
% If you have any questions feel free to contact
% ziga.emersic@fri.uni-lj.si
% ============================================================================================

\documentclass[9pt]{IEEEtran}

% basic
\usepackage[english]{babel}
\usepackage{graphicx,epstopdf,fancyhdr,amsmath,amsthm,amssymb,url,array,textcomp,svg,listings,hyperref,xcolor,colortbl,float,gensymb,longtable,supertabular,multicol,placeins}

 % `sumniki' in names
\usepackage[utf8x]{inputenc}

 % search and copy for `sumniki'
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\input{glyphtounicode}
\pdfgentounicode=1

% tidy figures
\graphicspath{{../figures/}}
\DeclareGraphicsExtensions{.pdf,.png,.jpg,.eps}

% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor trig-gs}

% ============================================================================================

\title{\vspace{0ex} %
Ear Recognition
\\ \large{Assignment \#3}\\ \normalsize{Image Based Biometrics 2020/21, Faculty of Computer and Information Science, University of Ljubljana}}
\author{ %
Jan~Jone≈°
\vspace{-4.0ex}
}

% ============================================================================================

\begin{document}

\maketitle

\begin{abstract}
    Ears as biometric modality for identity recognition has several advantages.
    This modality is universal and easily obtainable from images of people.
    On the other hand, focus of image-based biometric research lies elsewhere (e.g., face recognition).
    Therefore, high-quality datasets consisting of segmented and labeled ear images are scarce.
    Furthermore, deep learning techniques evolve quickly and they provide state-of-the-art solutions for wide range of image classification tasks.
    These techniques are certainly applicable to image-based biometry and ear recognition is one of those less researched.
    In this paper we train deep neural network classifier on readily-available annotated ear dataset.
    Due to low amount of data points available for training, we build our network upon model that is pre-trained on large image dataset from another domain.
    We are able to achieve accuracy 19.60~\% on unseen test data.
\end{abstract}

\section{Introduction}

Convolutional neural networks (CNNs) are deep neural networks that are state-of-the-art approach to solving various image-based tasks including segmentation and classification.
They have also been recently employed for ear recognition~\cite{emersic2017}.

In this paper we build and evaluate CNN model intended to be used as recognition stage in biometric pipeline with ear modality.
Our model accepts image of an ear at its input and produces identification of the subject at its output.
Input image is expected to be cropped, so that only the ear is visible.
For that, e.g., a separate CNN-based ear detector can be used as a previous stage in the biometric pipeline and then the whole pipeline can accept images of people as inputs.

Since ears are not prevalent modality in image-based authentication, high-quality datasets containing annotated ear images are scarce and they usually consist of relatively few datapoints.
We approach this problem in two ways:
\begin{enumerate}
    \item We build our model upon publicly available CNN model pre-trained for image classification.
          This model has been trained on datasets much larger than ours.
          We use its weights as our starting point and employ transfer learning to adapt this model for ear image classification.
    \item We analyze impact of image augmentation on the ear dataset used for training our CNN model.
          We hypothesize that image augmentation could improve the model's ability to generalize even from relatively small dataset because the input data are more varied.
\end{enumerate}

\section{Methodology}\label{sec:meth}

Our CNN model is based on EfficientNet-B0 model~\cite{efficientNet} pre-trained on ImageNet~\cite{imageNet} without its top fully-connected layer that was used for the original classification.
We instead append two fully-connected layers with 512 units, each followed by ReLU activation and dropout with rate 0.5.
The network ends with softmax activation to classify the subjects.
This layer has as many units as there are subjects, because we use a closed-set experimentation protocol.
During training we freeze EfficientNet weights and train only the appended layers.

We also experiment with image augmentation where each training image can be randomly flipped horizontally, be resized, cropped and have its brightness adjusted.

\section{Experiments and results}

We use dataset of ear images scraped from the Internet~\cite{awe}.
It contains data of 100 subjects, 10 cropped ear images per subject.
It is split into train, validation and test sets of 500, 250 and 250 images, respectively.

We evaluate the CNN performance using rank-1 and rank-5 recognition rates, cumulative match-score curve (CMC) and area under the CMC curve (AUCMC).

We train two models---one on the original training dataset (Model A) and another on augmented images as described in Section~\ref{sec:meth} (Model B).
Both models are trained with Adam optimizer using learning rate $10^{-3}$ for first 35 epochs and decreased to $10^{-4}$ for next 35 epochs.

CMC curve of Model A is slightly worse than that of Model B (Figure~\ref{fig:cmc}).
Accuracy of Model A is significantly better than that of Model B (Table~\ref{tab:metrics}).
These results tell us that image augmentations are not enough to make the CNN generalize well, most likely due to low amount of training data.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\columnwidth]{cmc}
    \caption{CMC curves on test set for models trained on original and augmented datasets, respectively.}
    \label{fig:cmc}
\end{figure}

\begin{table}[ht]
    \caption{Performance metrics of models on test set.}
    \label{tab:metrics}
    \centering
    \begin{tabular}{llll}
        Augmentations & Rank-1 [\%] & Rank-5 [\%] & AUCMC [\%] \\
        \hline
        No & 19.60 & 42.80 & 80.46 \\
        Yes & 14.40 & 32.00 & 78.53
    \end{tabular}
\end{table}

\section{Conclusion}
The trained CNN shows very good results as is and there is also some space for future improvement.
Image augmentation would help making the training dataset more diverse (e.g., horizontal/vertical flips, color transformations, cutouts, etc.).
Fine-tuning (a process where the pre-trained EfficientNet is also trained with low learning rate) usually also improves performance.
Finally, architecture of the CNN could be more complex (e.g., higher-level EfficientNet could be used) but that would also make training more computing-intensive and hence slower.

\bibliographystyle{IEEEtran}
\bibliography{bibliography}

\end{document}
